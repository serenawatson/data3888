{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "642e620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "from requests_html import HTML\n",
    "from requests_html import HTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random\n",
    "from k_means_constrained import KMeansConstrained\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5727e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(3888)\n",
    "\n",
    "def get_variable_groups():\n",
    "    variable_groups = {}\n",
    "    variable_groups[\"covid\"] = ['new_cases_smoothed_per_million', 'stringency_index', 'positive_rate', 'new_vaccinations_smoothed_per_million']\n",
    "    variable_groups[\"infrastructure_quality_and_availability\"] = ['tourist_service', 'air_transport', 'ground_port']\n",
    "    variable_groups[\"health_and_safety\"] = ['safety_security', 'health_hygiene']\n",
    "    variable_groups[\"cost\"] = ['price_competitiveness']\n",
    "    \n",
    "    # POIs\n",
    "    variable_groups[\"fun\"] = ['amusementparks', 'nightlife']\n",
    "    variable_groups[\"nature\"] = ['beaches', 'camping', 'exploringnature']\n",
    "    variable_groups[\"food\"] = ['eatingout']\n",
    "    variable_groups[\"museums\"] = ['museums']\n",
    "    variable_groups[\"showstheatresandmusic\"] = ['showstheatresandmusic']\n",
    "    variable_groups[\"wellness\"] = ['wellness']\n",
    "    variable_groups[\"wildlife\"] = ['zoos']\n",
    "\n",
    "    return variable_groups\n",
    "\n",
    "def convert_interest_level_to_weighting(interested):\n",
    "    interested_mapping = {\n",
    "        True: 100,\n",
    "        False: 1\n",
    "    }\n",
    "    \n",
    "    return interested_mapping[interested]\n",
    "\n",
    "def convert_interests_to_col_weightings(interests):\n",
    "    variable_groups = get_variable_groups()\n",
    "    \n",
    "    col_weightings = {}\n",
    "    \n",
    "    for interest in interests:\n",
    "        cols = variable_groups[interest]\n",
    "        weighting = convert_interest_level_to_weighting(interests[interest])\n",
    "        for col in cols:\n",
    "            col_weightings[col] = weighting\n",
    "            \n",
    "    return col_weightings\n",
    "\n",
    "def get_all_features():\n",
    "    variable_groups = get_variable_groups()\n",
    "\n",
    "    all_features = []\n",
    "    for group in variable_groups.values():\n",
    "        for col in group:\n",
    "            all_features.append(col)\n",
    "\n",
    "    return all_features\n",
    "\n",
    "def get_all_cols():\n",
    "    cols = get_all_features()\n",
    "    cols.append(\"iso_code\")\n",
    "    cols.append(\"location\")\n",
    "    cols.append(\"advice\")\n",
    "    cols.append(\"description\")\n",
    "    cols.append(\"continent\")\n",
    "    cols.append(\"date\")\n",
    "\n",
    "    return cols\n",
    "\n",
    "def read_original_data():\n",
    "    df = pd.read_csv(\"data/data.txt\")\n",
    "    df = df.drop(columns='Unnamed: 0')\n",
    "\n",
    "    df = df.rename(columns = {'tourist_service_index': 'tourist_service'})\n",
    "\n",
    "    df_without_covid = df.drop(columns=['new_cases_per_million', \n",
    "                                    'new_cases_smoothed_per_million', \n",
    "                                    'stringency_index', \n",
    "                                    'positive_rate', \n",
    "                                    'human_development_index', \n",
    "                                    'international_travel_controls',\n",
    "                                    'cost_living_index',\n",
    "                                    'date',\n",
    "                                    'location',\n",
    "                                    'continent'])\n",
    "\n",
    "    df_without_covid = df_without_covid.drop_duplicates()\n",
    "    df_without_covid = df_without_covid.reset_index()\n",
    "    df_without_covid = df_without_covid.drop(columns=['index'])\n",
    "\n",
    "    return df_without_covid\n",
    "\n",
    "def read_tourism_data():\n",
    "    full_tourism = pd.read_csv(\"data/full_tourism.csv\")\n",
    "    full_tourism = full_tourism[full_tourism[\"Country ISO3\"] != \"AUS\"]\n",
    "\n",
    "    indicators = {\n",
    "                    'WEF Infrastructure subindex, 1-7 (best)': 'infrastructure', \n",
    "                    'WEF Natural and cultural resources subindex, 1-7 (best)': 'natural_cultural_resources',\n",
    "                    'WEF Safety and security pillar, 1-7 (best)': 'safety_security',\n",
    "                    'WEF Health and hygiene, 1-7 (best)': 'health_hygiene',\n",
    "                    'WEF Price competitiveness in the Travel and Tourism Industry pillar, 1-7 (best)': 'price_competitiveness',\n",
    "                    'WEF Air transport infrastructure, 1-7 (best)': 'air_transport',\n",
    "                    'WEF Ground and port infrastructure, 1-7 (best)': 'ground_port'\n",
    "    }\n",
    "\n",
    "    full_tourism_req_indicators = full_tourism[full_tourism[\"Indicator\"].isin(indicators)]\n",
    "    full_tourism_req_indicators = full_tourism_req_indicators[['Country ISO3', 'Indicator', 'Subindicator Type', '2019']]\n",
    "    full_tourism_req_indicators = full_tourism_req_indicators[full_tourism[\"Subindicator Type\"] == \"Value\"]\n",
    "    full_tourism_req_indicators = full_tourism_req_indicators.drop(columns = ['Subindicator Type'])\n",
    "    full_tourism_req_indicators = full_tourism_req_indicators.rename(columns = {'Country ISO3': 'iso_code'})\n",
    "    full_tourism_req_indicators = full_tourism_req_indicators.set_index('iso_code')\n",
    "\n",
    "    inds = pd.DataFrame()\n",
    "\n",
    "    for ind in indicators.keys():\n",
    "        inds[indicators[ind]] = full_tourism_req_indicators[full_tourism_req_indicators[\"Indicator\"] == ind].drop(columns = [\"Indicator\"]).rename(columns = {'2019': indicators[ind]})[indicators[ind]]\n",
    "\n",
    "    return inds\n",
    "\n",
    "def read_live_covid_data():\n",
    "    covid = pd.read_csv(\"https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv\")\n",
    "\n",
    "    covid['date'] = pd.to_datetime(covid['date'], format='%Y-%m-%d')\n",
    "\n",
    "    covid = covid[covid['date'] >= datetime.now() - timedelta(days = 30)]\n",
    "\n",
    "    return covid\n",
    "\n",
    "def read_poi_data():\n",
    "    poi = pd.read_csv(\"data/triposo_poi.csv\", index_col = 0)\n",
    "    poi = poi.apply(pd.to_numeric)\n",
    "    \n",
    "    return poi\n",
    "\n",
    "def read_iso_loc_data():\n",
    "    df = pd.read_csv(\"data/data.txt\")\n",
    "    df = df.drop(columns='Unnamed: 0')\n",
    "\n",
    "    iso_location = df[[\"iso_code\", \"location\"]].drop_duplicates()\n",
    "\n",
    "    return iso_location\n",
    "\n",
    "def iso_code_to_loc(iso_code, iso_location):\n",
    "    return iso_location[iso_location[\"iso_code\"] == iso_code][\"location\"].iloc[0]\n",
    "\n",
    "def loc_to_iso_code(loc, iso_location):\n",
    "    return iso_location[iso_location[\"location\"] == loc][\"iso_code\"].iloc[0]\n",
    "\n",
    "def read_smartraveller_data():\n",
    "    # https://practicaldatascience.co.uk/data-science/how-to-read-an-rss-feed-in-python\n",
    "\n",
    "    def get_source(url):\n",
    "        \"\"\"Return the source code for the provided URL. \n",
    "\n",
    "        Args: \n",
    "            url (string): URL of the page to scrape.\n",
    "\n",
    "        Returns:\n",
    "            response (object): HTTP response object from requests_html. \n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            session = HTMLSession()\n",
    "            response = session.get(url)\n",
    "            return response\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    def get_feed(url):\n",
    "        \"\"\"Return a Pandas dataframe containing the RSS feed contents.\n",
    "\n",
    "        Args: \n",
    "            url (string): URL of the RSS feed to read.\n",
    "\n",
    "        Returns:\n",
    "            df (dataframe): Pandas dataframe containing the RSS feed contents.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = get_source(url)\n",
    "        \n",
    "        df = pd.DataFrame(columns = ['title', 'pubDate', 'guid', 'description'])\n",
    "\n",
    "        with response as r:\n",
    "            items = r.html.find(\"item\", first=False)\n",
    "\n",
    "            for item in items:        \n",
    "\n",
    "                title = item.find('title', first=True).text\n",
    "                pubDate = item.find('pubDate', first=True).text\n",
    "                guid = item.find('guid', first=True).text\n",
    "                description = item.find('description', first=True).text\n",
    "\n",
    "                row = {'title': [title], 'pubDate': [pubDate], 'guid': [guid], 'description': [description]}\n",
    "                df = pd.concat([df, pd.DataFrame.from_dict(row)])\n",
    "\n",
    "        return df\n",
    "\n",
    "    travel_advice = get_feed(\"https://www.smartraveller.gov.au/countries/documents/index.rss\")\n",
    "\n",
    "    travel_advice = travel_advice[travel_advice[\"title\"] != \"No travel advice\"]\n",
    "\n",
    "    travel_advice = travel_advice.drop(columns=['guid'])\n",
    "\n",
    "    replacements = {\n",
    "        \"United States of America\": \"United States\",\n",
    "        \"Israel and the Palestinian Territories\": \"Israel\",\n",
    "        \"South Korea (Republic of Korea)\": \"South Korea\"\n",
    "    }\n",
    "\n",
    "    for replacement in replacements:\n",
    "        travel_advice.replace(replacement, replacements[replacement], inplace = True)\n",
    "\n",
    "    travel_advice.rename(columns={\"title\": \"location\", \"description\": \"advice\"}, inplace = True)\n",
    "\n",
    "    travel_advice[\"advice\"] = [BeautifulSoup(s, \"lxml\").text for s in travel_advice[\"advice\"]]\n",
    "\n",
    "    return travel_advice\n",
    "\n",
    "def read_triposo_data():\n",
    "    descriptions = pd.read_csv(\"country_descriptions_cleaned_2.csv\")\n",
    "\n",
    "    return descriptions\n",
    "\n",
    "def integrate_all_data():\n",
    "    # reading in all data\n",
    "    original = read_original_data()\n",
    "    tourism = read_tourism_data()\n",
    "    covid = read_live_covid_data()\n",
    "    poi = read_poi_data()\n",
    "    smartraveller = read_smartraveller_data()\n",
    "    triposo = read_triposo_data()\n",
    "\n",
    "    # merging\n",
    "    full = pd.merge(original, tourism, on=\"iso_code\")\n",
    "    full = pd.merge(full, covid, on=\"iso_code\")\n",
    "    full = pd.merge(full, poi, on=\"iso_code\")\n",
    "\n",
    "    full = pd.merge(full, smartraveller, on=\"location\")\n",
    "    full = pd.merge(full, triposo, on=\"iso_code\")\n",
    "\n",
    "    full = full[full[\"iso_code\"] != \"AUS\"]\n",
    "    \n",
    "    return full[get_all_cols()]\n",
    "\n",
    "def prepare_data_for_clustering(data, continents, weightings):\n",
    "    print(data.columns)\n",
    "    \n",
    "    # continents filtering\n",
    "    data = data[data[\"continent\"].isin(continents)]\n",
    "    data_no_quant = list(set(data.columns).difference(set(data.select_dtypes(include=[np.number]).columns)))\n",
    "    data_no_quant.remove(\"date\")\n",
    "\n",
    "    medians = data.groupby([\"iso_code\"]).median()\n",
    "    medians = medians.fillna(data.median())\n",
    "\n",
    "    if medians.shape[0] == 0:\n",
    "        return medians, medians, data[data_no_quant]\n",
    "\n",
    "    iso_code = medians.index\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    medians_scaled = scaler.fit_transform(medians)\n",
    "\n",
    "    cols = list(data.columns)\n",
    "\n",
    "    to_remove = ['iso_code', 'continent', 'location', 'date', 'advice', 'description']\n",
    "\n",
    "    for col in to_remove:\n",
    "        cols.remove(col)\n",
    "                \n",
    "    medians_scaled = pd.DataFrame(medians_scaled, \n",
    "                                columns = cols, \n",
    "                                index = iso_code)\n",
    "\n",
    "    for col in medians_scaled.columns:\n",
    "        medians_scaled[col] = medians_scaled[col].apply(lambda x: x * weightings[col])\n",
    "\n",
    "    if len(medians_scaled.columns) > 2:\n",
    "        pca = PCA(n_components=2)\n",
    "        pc = pca.fit_transform(medians_scaled)\n",
    "        medians_scaled = pd.DataFrame(data = pc, columns = ['PC1', 'PC2'], index = medians_scaled.index)\n",
    "\n",
    "    return medians_scaled, medians, data[data_no_quant]\n",
    "\n",
    "def generate_best_cluster(scaled_data, interested):\n",
    "    clf = KMeansConstrained(\n",
    "            n_clusters=scaled_data.shape[0]//10,\n",
    "            size_min=10,\n",
    "            size_max=12,\n",
    "            random_state=3888\n",
    "    )\n",
    "    \n",
    "    labels = clf.fit_predict(scaled_data)\n",
    "    \n",
    "    clusters = {}\n",
    "    iso_location = read_iso_loc_data()\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        if label in clusters:\n",
    "            clusters[label].append(list(medians_scaled.index)[i])\n",
    "        else:\n",
    "            clusters[label] = [list(medians_scaled.index)[i]]\n",
    "            \n",
    "    col_weightings = convert_interests_to_col_weightings(interested)\n",
    "        \n",
    "    cols_of_interest = [col for col in col_weightings if col_weightings[col] == 100]\n",
    "    \n",
    "    cluster_rating = {}\n",
    "\n",
    "    for cluster_label in clusters:\n",
    "        all_ratings = []\n",
    "        \n",
    "        for col in cols_of_interest:\n",
    "            cluster_col_vals = list(medians.loc[clusters[cluster_label]][col])\n",
    "            for val in cluster_col_vals:\n",
    "                all_ratings.append(val)\n",
    "        \n",
    "        cluster_rating[cluster_label] = mean(all_ratings)\n",
    "        \n",
    "    best_cluster = sorted(cluster_rating, key=lambda x: cluster_rating[x], reverse = True)[0]\n",
    "        \n",
    "    return clusters[best_cluster]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "876bdfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "interested = {}\n",
    "\n",
    "interested[\"covid\"] = False\n",
    "interested[\"infrastructure_quality_and_availability\"] = False\n",
    "interested[\"health_and_safety\"] = True\n",
    "interested[\"cost\"] = False\n",
    "interested[\"fun\"] = True\n",
    "interested[\"nature\"] = False\n",
    "interested[\"food\"] = False\n",
    "interested[\"museums\"] = False\n",
    "interested[\"showstheatresandmusic\"] = False\n",
    "interested[\"wellness\"] = False\n",
    "interested[\"wildlife\"] = False\n",
    "\n",
    "weightings = convert_interests_to_col_weightings(interested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4cc7daf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11268/1174010211.py:102: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  full_tourism_req_indicators = full_tourism_req_indicators[full_tourism[\"Subindicator Type\"] == \"Value\"]\n"
     ]
    }
   ],
   "source": [
    "countries_data = integrate_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "718af265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['new_cases_smoothed_per_million', 'stringency_index', 'positive_rate',\n",
      "       'new_vaccinations_smoothed_per_million', 'tourist_service',\n",
      "       'air_transport', 'ground_port', 'safety_security', 'health_hygiene',\n",
      "       'price_competitiveness', 'amusementparks', 'nightlife', 'beaches',\n",
      "       'camping', 'exploringnature', 'eatingout', 'museums',\n",
      "       'showstheatresandmusic', 'wellness', 'zoos', 'iso_code', 'location',\n",
      "       'advice', 'description', 'continent', 'date'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11268/1174010211.py:250: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  medians = medians.fillna(data.median())\n",
      "/tmp/ipykernel_11268/1174010211.py:250: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  medians = medians.fillna(data.median())\n"
     ]
    }
   ],
   "source": [
    "medians_scaled, medians, data_no_quant = prepare_data_for_clustering(countries_data, [\"Asia\", \"Europe\"], weightings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cf43b906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BEL', 'CHN', 'DEU', 'DNK', 'ESP', 'FRA', 'GBR', 'ITA', 'JPN', 'NLD', 'TWN']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best_cluster(medians_scaled, interested)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
