{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e2cbfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import more_itertools\n",
    "import random\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "from analytics_clustering import *\n",
    "from analytics_helper_clustering import *\n",
    "from analytics import *\n",
    "from analytics_helper import *\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cd97d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hides warnings - these do not affect code functionality\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dbd63df",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(3888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b991a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_data = integrate_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d9bc3c",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bad3340",
   "metadata": {},
   "source": [
    "Mean silhouette score across\n",
    "\n",
    "- 100 randomly-chosen interest combinations, and\n",
    "- all possible region combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4580f6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b3b0a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_combs = list(itertools.product([False, True], repeat=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f628cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "interests = [\"covid\", \n",
    "             \"infrastructure_quality_and_availability\",\n",
    "             \"health_and_safety\",\n",
    "             \"cost\",\n",
    "             \"fun\",\n",
    "             \"nature\",\n",
    "             \"food\",\n",
    "             \"museums\",\n",
    "             \"showstheatresandmusic\",\n",
    "             \"wellness\",\n",
    "             \"wildlife\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d5f190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_combs_chosen = random.sample(interest_combs, 100)\n",
    "\n",
    "while [False] * 15 in interest_combs_chosen:\n",
    "    interest_combs_chosen = random.sample(interest_combs, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "383e2271",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_combs = list(more_itertools.powerset(['Asia-Pacific', 'Europe and Africa', 'Americas']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32c8c6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for interest_comb in interest_combs_chosen:  \n",
    "    for regions in region_combs:\n",
    "        interested = {}\n",
    "        for i, interest in enumerate(interests):\n",
    "            interested[interest] = interest_comb[i]\n",
    "\n",
    "        if list(interested.values()).count(True) != 0 and len(regions) != 0:\n",
    "            weightings = convert_interests_to_col_weightings(interested)\n",
    "            medians_scaled_pca, medians_scaled = prepare_data_for_clustering(countries_data, regions, weightings)\n",
    "\n",
    "            scores.append(compute_silhouette_score(medians_scaled_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a62fe5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3633255640966533"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3490698c",
   "metadata": {},
   "source": [
    "**Observation:** Our silhouette score is average; there is _some_ clustering structure in our data, though it is not very well-defined.\n",
    "\n",
    "However, for our purposes, it doesn't really matter whether our clusters are _extremely_ well-defined or not; either way, each cluster will still be a group of fairly-similar countries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e33df3",
   "metadata": {},
   "source": [
    "# k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "daaad05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neighbours = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f55151ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_location = read_iso_loc_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e899016",
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_combs_10NN = list(more_itertools.powerset(interests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b30630b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_combs_10NN_chosen = random.sample(interest_combs_10NN, 3)\n",
    "\n",
    "while [False] * 15 in interest_combs_chosen:\n",
    "    interest_combs_chosen = random.sample(interest_combs, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef22361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen_interests:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('covid',\n",
       "  'infrastructure_quality_and_availability',\n",
       "  'health_and_safety',\n",
       "  'nature',\n",
       "  'museums',\n",
       "  'showstheatresandmusic',\n",
       "  'wellness',\n",
       "  'wildlife'),\n",
       " ('covid',),\n",
       " ('fun', 'nature', 'food', 'wellness')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"chosen_interests:\")\n",
    "interest_combs_10NN_chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8a82716",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_10NN_chosen = random.sample(list(iso_location['location'].drop_duplicates()), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22e8ff4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen_countries:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Slovenia', 'Lithuania', 'Colombia', 'Vietnam', 'Norway']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"chosen_countries:\")\n",
    "countries_10NN_chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "869d4056",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = ['braycurtis', 'canberra', 'chebyshev', 'cityblock', 'correlation',\n",
    "               'cosine', 'euclidean', 'manhattan', 'minkowski']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae99b2b",
   "metadata": {},
   "source": [
    "## Single model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7886228a",
   "metadata": {},
   "source": [
    "1. We randomly choose 3 interest combinations, $\\text{chosen_interests}$.\n",
    "2. We randomly choose 5 countries, $\\text{chosen_countries}$.\n",
    "3. For each pair of distance metrics $d_1, d_2$:\n",
    "    - For each $i$ in $\\text{chosen_interests}$:\n",
    "        - For each $c$ in $\\text{chosen_countries}$:\n",
    "            - we compute proportion of similarity between sets of countries produced by \n",
    "                - 10-NN for $c$ when $d_1$ is used as distance metric (with columns in $i$ weighted more), and \n",
    "                - 10-NN for $c$ when $d_2$ is used as distance metric (with columns in $i$ weighted more).\n",
    "5. We compute the average $a$ of all proportion of similarity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2b06b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_pairs = list(itertools.combinations(all_metrics, r=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af00b772",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prop_similarity = []\n",
    "\n",
    "for pair in metrics_pairs:\n",
    "    regions = ['Asia-Pacific', 'Europe and Africa', 'Americas']\n",
    "    \n",
    "    for interests in interest_combs_10NN_chosen:  \n",
    "    \n",
    "        if len(interests) > 0 and len(regions) > 0:\n",
    "            continents = convert_regions_to_continents(regions)\n",
    "\n",
    "            cols_of_interest = convert_interests_to_cols(interests)\n",
    "            weightings = generate_feature_weightings_dict(cols_of_interest)\n",
    "\n",
    "            for country in countries_10NN_chosen:  \n",
    "                medians_scaled, medians, data_no_quant = prepare_data_for_nn(countries_data, country, continents, weightings)\n",
    "\n",
    "                if not loc_to_iso_code(country, iso_location) in medians.index:\n",
    "                    continue\n",
    "\n",
    "                neighbours_all_metrics = list(generate_final_df_w_nn(country,\n",
    "                                                                 medians_scaled,\n",
    "                                                                 medians,\n",
    "                                                                 data_no_quant,\n",
    "                                                                 num_neighbours = num_neighbours,\n",
    "                                                                 dist_metrics=[pair[0]])['5NN'])[0]\n",
    "\n",
    "                neighbours_metric_missing = list(generate_final_df_w_nn(country,\n",
    "                                                                 medians_scaled,\n",
    "                                                                 medians,\n",
    "                                                                 data_no_quant,\n",
    "                                                                 num_neighbours = num_neighbours,\n",
    "                                                                 dist_metrics=[pair[1]])['5NN'])[0]\n",
    "\n",
    "                neighbours_intersect = set(neighbours_all_metrics).intersection(neighbours_metric_missing)    \n",
    "                sim = len(neighbours_intersect)/num_neighbours\n",
    "\n",
    "                prop_similarity.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37fc9e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(prop_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf5c847",
   "metadata": {},
   "source": [
    "**Observation:** Changing our distance metric leads to a _non-negligible change in result_ (on average) - our model is not very stable, not robust to change in distance metric.\n",
    "\n",
    "**Solution:** Use an ensemble. Each model in ensemble is a 10-NN model using a *different distance metric*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d9d481",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581c8f6b",
   "metadata": {},
   "source": [
    "1. We randomly choose 3 interest combinations, $\\text{chosen_interests}$.\n",
    "2. We randomly choose 5 countries, $\\text{chosen_countries}$.\n",
    "3. For each distance metric $d$:\n",
    "    - For each $i$ in $\\text{chosen_interests}$:\n",
    "        - For each $c$ in $\\text{chosen_countries}$:\n",
    "            - we compute the proportion of similarity between sets of countries returned by\n",
    "                - 10-NN for $c$ with full ensemble (and with columns in $i$ weighted more), and\n",
    "                - 10-NN for $c$ with full ensemble **minus $d$** (and with columns in $i$ weighted more).\n",
    "    - We compute the average $a$ of all the proportion of similarity values corresponding to $d$. $a$ becomes the overall \"score\" for $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e813072",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prop_similarity = {}\n",
    "\n",
    "for metric in all_metrics:\n",
    "    dist_metrics = list(set(all_metrics) - set([metric]))\n",
    "    regions = ['Asia-Pacific', 'Europe and Africa', 'Americas']\n",
    "    \n",
    "    for interests in interest_combs_10NN_chosen:  \n",
    "    \n",
    "        if len(interests) > 0 and len(regions) > 0:\n",
    "            continents = convert_regions_to_continents(regions)\n",
    "\n",
    "            cols_of_interest = convert_interests_to_cols(interests)\n",
    "            weightings = generate_feature_weightings_dict(cols_of_interest)\n",
    "\n",
    "            for country in countries_10NN_chosen:  \n",
    "                medians_scaled, medians, data_no_quant = prepare_data_for_nn(countries_data, country, continents, weightings)\n",
    "\n",
    "                if not loc_to_iso_code(country, iso_location) in medians.index:\n",
    "                    continue\n",
    "\n",
    "                neighbours_all_metrics = list(generate_final_df_w_nn(country,\n",
    "                                                                 medians_scaled,\n",
    "                                                                 medians,\n",
    "                                                                 data_no_quant,\n",
    "                                                                 num_neighbours = num_neighbours,\n",
    "                                                                 dist_metrics=all_metrics)['5NN'])[0]\n",
    "\n",
    "                neighbours_metric_missing = list(generate_final_df_w_nn(country,\n",
    "                                                                 medians_scaled,\n",
    "                                                                 medians,\n",
    "                                                                 data_no_quant,\n",
    "                                                                 num_neighbours = num_neighbours,\n",
    "                                                                 dist_metrics=dist_metrics)['5NN'])[0]\n",
    "\n",
    "                neighbours_intersect = set(neighbours_all_metrics).intersection(neighbours_metric_missing)    \n",
    "                sim = len(neighbours_intersect)/num_neighbours\n",
    "\n",
    "                if not metric in prop_similarity:\n",
    "                    prop_similarity[metric] = [sim]\n",
    "                else:\n",
    "                    prop_similarity[metric].append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1e88b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_prop_similarity = {}\n",
    "\n",
    "for metric in prop_similarity.keys():\n",
    "    avg_prop_similarity[metric] = mean(prop_similarity[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce7c5c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'braycurtis': 0.9533333333333334,\n",
       " 'canberra': 0.98,\n",
       " 'chebyshev': 0.98,\n",
       " 'cityblock': 0.9533333333333334,\n",
       " 'correlation': 0.98,\n",
       " 'cosine': 0.98,\n",
       " 'euclidean': 0.98,\n",
       " 'manhattan': 0.9533333333333334,\n",
       " 'minkowski': 0.98}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_prop_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdcda58",
   "metadata": {},
   "source": [
    "**Observation:** Removing any single model from ensemble leads to only a slight change in result. Thus, we ensure that *no one distance metric completely determines 10 nearest neighbours*, and so our model is very robust to removal/addition of distance metrics. Whereas when we used just 1 model/distance metric, changing the single distance metric used led to considerably more variability in result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
